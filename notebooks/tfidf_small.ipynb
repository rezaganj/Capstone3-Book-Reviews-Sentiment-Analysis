{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "101cf853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/reza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbee1b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import string\n",
    "import time\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from joblib import dump , load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c893f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/amazon_reviews_small.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18660858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review_headline'] + '. ' + df['review_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86144103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_sentiments'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c62dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['star_rating'].isin([4, 5]), 'review_sentiments'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8c258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['review_headline', 'review_body', 'star_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ae57fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good book. This is a very good book. I recomme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the Marenon Chronically Series. Loved all thre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOD READ. Made me think about the fine line b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excellant family devotion. I had been looking ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great read. So entertaining, not a dull moment...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Awesome. I haven't read a book like this in a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Absolutely GREAT. I started reading it because...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Sicko. These are two writers with some serious...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Just too small. It was just too small for the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>enjoyed it a lot. I liked the story a lot. And...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  review_sentiments\n",
       "0     Good book. This is a very good book. I recomme...                  1\n",
       "1     the Marenon Chronically Series. Loved all thre...                  1\n",
       "2     GOOD READ. Made me think about the fine line b...                  1\n",
       "3     excellant family devotion. I had been looking ...                  1\n",
       "4     Great read. So entertaining, not a dull moment...                  1\n",
       "...                                                 ...                ...\n",
       "9995  Awesome. I haven't read a book like this in a ...                  1\n",
       "9996  Absolutely GREAT. I started reading it because...                  1\n",
       "9997  Sicko. These are two writers with some serious...                  0\n",
       "9998  Just too small. It was just too small for the ...                  0\n",
       "9999  enjoyed it a lot. I liked the story a lot. And...                  1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "552fb19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample_df(df, col, n_samples):\n",
    "    n = min(n_samples, df[col].value_counts().min())\n",
    "    df_ = df.groupby(col).apply(lambda x: x.sample(n))\n",
    "    df_.index = df_.index.droplevel(0)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1a42bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = stratified_sample_df(df, 'review_sentiments', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bdf6699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "1    1000\n",
       "Name: review_sentiments, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small['review_sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96181fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_stopwords = stopwords.words('english')+['else',\"ya\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c187b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text, stem_flag=False, lem_flag=True, lst_stopwords=None):\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = text.replace('\\\\n',' ')\n",
    "    text = text.replace('\\n',' ')\n",
    "    text = re.sub(r'[^\\w\\s]',' ',str(text).lower().strip())\n",
    "    text = re.sub('[^a-z\\s]', ' ', str(text).lower().strip())\n",
    "    text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", str(text).lower().strip())\n",
    "    text = re.sub(' 0 ',' ',str(text).lower().strip())\n",
    "    text = re.sub(' 00 ',' ',str(text).lower().strip())\n",
    "    text = re.sub(' 000 ',' ',str(text).lower().strip())\n",
    "    \n",
    "    lst_text = text.split()\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in lst_stopwords]\n",
    "    if stem_flag == True:\n",
    "        ps = PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "    if lem_flag == True:\n",
    "        lem = WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "    lst_text = \" \".join(lst_text)\n",
    "    return lst_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1789fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['review_clean'] = df_small['review'].apply(lambda x: text_cleaning(x, \n",
    "                                                                            stem_flag=False, \n",
    "                                                                            lem_flag=True, \n",
    "                                                                            lst_stopwords=lst_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fb46d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_small['review_clean']\n",
    "y = df_small['review_sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9121da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_small['review'], \n",
    "                                                    df_small['review_sentiments'], \n",
    "                                                    stratify=df_small['review_sentiments'], \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32499886",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_features=10000,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47cceb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da623c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcf1152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e7f562b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29877a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "model_predictions(xgb,XX_train.toarray(),y_train, XX_test.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53dfeb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "dtrain = xgb.DMatrix(XX_train, label=y_train)\n",
    "dtest = xgb.DMatrix(XX_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd9a946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters via map\n",
    "param = {'objective':'binary:hinge', 'eval_metric':'logloss', 'colsample_bytree':0.5, \n",
    "         'max_depth':5, 'nthread':16, 'subsample':0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c741623",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 100\n",
    "xgb_small = xgb.train(param, dtrain, num_boost_round=num_round, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c8c1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "preds = xgb_small.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0230f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       250\n",
      "           1       0.71      0.65      0.68       250\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.70      0.69      0.69       500\n",
      "weighted avg       0.70      0.69      0.69       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report \\n\", classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9777d229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  \n",
      " [[185  65]\n",
      " [ 88 162]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:  \\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a8a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
