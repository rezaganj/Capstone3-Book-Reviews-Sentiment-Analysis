{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aa180dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reza/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "## for data\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## for processing\n",
    "import re\n",
    "import nltk\n",
    "## for bag-of-words\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
    "## for explainer\n",
    "# from lime import lime_text\n",
    "## for word embedding\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "## for deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "## for bert language model\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f805e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/amazon_reviews_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c321594b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    6825\n",
       "4    2164\n",
       "3     659\n",
       "2     231\n",
       "1     121\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['star_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ea1c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review_headline'] + '. ' + df['review_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "903b52a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_sentiments'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3ad8229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reza/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['review_sentiments'][df['star_rating'].isin([4, 5])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9e86a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review</th>\n",
       "      <th>review_sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Good book</td>\n",
       "      <td>This is a very good book. I recommend it for f...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good book. This is a very good book. I recomme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the Marenon Chronically Series</td>\n",
       "      <td>Loved all three novels!  Morrow is a good stor...</td>\n",
       "      <td>5</td>\n",
       "      <td>the Marenon Chronically Series. Loved all thre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GOOD READ</td>\n",
       "      <td>Made me think about the fine line between life...</td>\n",
       "      <td>5</td>\n",
       "      <td>GOOD READ. Made me think about the fine line b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>excellant family devotion</td>\n",
       "      <td>I had been looking for a family devotional gea...</td>\n",
       "      <td>5</td>\n",
       "      <td>excellant family devotion. I had been looking ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Great read</td>\n",
       "      <td>So entertaining, not a dull moment in the enti...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great read. So entertaining, not a dull moment...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>I haven't read a book like this in a while.lov...</td>\n",
       "      <td>5</td>\n",
       "      <td>Awesome. I haven't read a book like this in a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>Absolutely GREAT</td>\n",
       "      <td>I started reading it because it was on my sons...</td>\n",
       "      <td>5</td>\n",
       "      <td>Absolutely GREAT. I started reading it because...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>Sicko</td>\n",
       "      <td>These are two writers with some serious macabr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sicko. These are two writers with some serious...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>Just too small</td>\n",
       "      <td>It was just too small for the kindle. I could ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Just too small. It was just too small for the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>enjoyed it a lot</td>\n",
       "      <td>I liked the story a lot. And am looking forwar...</td>\n",
       "      <td>5</td>\n",
       "      <td>enjoyed it a lot. I liked the story a lot. And...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                 review_headline  \\\n",
       "0              0                       Good book   \n",
       "1              1  the Marenon Chronically Series   \n",
       "2              2                       GOOD READ   \n",
       "3              3       excellant family devotion   \n",
       "4              4                      Great read   \n",
       "...          ...                             ...   \n",
       "9995        9995                         Awesome   \n",
       "9996        9996                Absolutely GREAT   \n",
       "9997        9997                           Sicko   \n",
       "9998        9998                  Just too small   \n",
       "9999        9999                enjoyed it a lot   \n",
       "\n",
       "                                            review_body  star_rating  \\\n",
       "0     This is a very good book. I recommend it for f...            5   \n",
       "1     Loved all three novels!  Morrow is a good stor...            5   \n",
       "2     Made me think about the fine line between life...            5   \n",
       "3     I had been looking for a family devotional gea...            5   \n",
       "4     So entertaining, not a dull moment in the enti...            5   \n",
       "...                                                 ...          ...   \n",
       "9995  I haven't read a book like this in a while.lov...            5   \n",
       "9996  I started reading it because it was on my sons...            5   \n",
       "9997  These are two writers with some serious macabr...            1   \n",
       "9998  It was just too small for the kindle. I could ...            2   \n",
       "9999  I liked the story a lot. And am looking forwar...            5   \n",
       "\n",
       "                                                 review  review_sentiments  \n",
       "0     Good book. This is a very good book. I recomme...                  1  \n",
       "1     the Marenon Chronically Series. Loved all thre...                  1  \n",
       "2     GOOD READ. Made me think about the fine line b...                  1  \n",
       "3     excellant family devotion. I had been looking ...                  1  \n",
       "4     Great read. So entertaining, not a dull moment...                  1  \n",
       "...                                                 ...                ...  \n",
       "9995  Awesome. I haven't read a book like this in a ...                  1  \n",
       "9996  Absolutely GREAT. I started reading it because...                  1  \n",
       "9997  Sicko. These are two writers with some serious...                  0  \n",
       "9998  Just too small. It was just too small for the ...                  0  \n",
       "9999  enjoyed it a lot. I liked the story a lot. And...                  1  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed502f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0', 'review_headline', 'review_body', 'star_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51b14da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good book. This is a very good book. I recomme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the Marenon Chronically Series. Loved all thre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOD READ. Made me think about the fine line b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excellant family devotion. I had been looking ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great read. So entertaining, not a dull moment...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Awesome. I haven't read a book like this in a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Absolutely GREAT. I started reading it because...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Sicko. These are two writers with some serious...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Just too small. It was just too small for the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>enjoyed it a lot. I liked the story a lot. And...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  review_sentiments\n",
       "0     Good book. This is a very good book. I recomme...                  1\n",
       "1     the Marenon Chronically Series. Loved all thre...                  1\n",
       "2     GOOD READ. Made me think about the fine line b...                  1\n",
       "3     excellant family devotion. I had been looking ...                  1\n",
       "4     Great read. So entertaining, not a dull moment...                  1\n",
       "...                                                 ...                ...\n",
       "9995  Awesome. I haven't read a book like this in a ...                  1\n",
       "9996  Absolutely GREAT. I started reading it because...                  1\n",
       "9997  Sicko. These are two writers with some serious...                  0\n",
       "9998  Just too small. It was just too small for the ...                  0\n",
       "9999  enjoyed it a lot. I liked the story a lot. And...                  1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "033fe8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample_df(df, col, n_samples):\n",
    "    n = min(n_samples, df[col].value_counts().min())\n",
    "    df_ = df.groupby(col).apply(lambda x: x.sample(n))\n",
    "    df_.index = df_.index.droplevel(0)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d940d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = stratified_sample_df(df, 'review_sentiments', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe42ca8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "1    1000\n",
       "Name: review_sentiments, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small['review_sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54fb9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e650af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a134289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_lst = df_small['review'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c487ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenizer(df_small_lst, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24925ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d54bde52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "744e5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(df_small['review'], \n",
    "                                                  df_small['review_sentiments'], \n",
    "                                                  stratify=df_small['review_sentiments'], \n",
    "                                                  test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3c090e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(X_temp, y_temp, stratify=y_temp, \n",
    "                                                    test_size=500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5124d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = tokenizer(X_train.to_list(), padding=\"max_length\", truncation=True)\n",
    "tf_eval_dataset = tokenizer(X_eval.to_list(), padding=\"max_length\", truncation=True)\n",
    "tf_test_dataset = tokenizer(X_test.to_list(), padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c68645c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\",\n",
    "                                                             num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a9def8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-5703a867526a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf_train_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_tf_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_tf_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_tf_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0meval_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf_eval_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-5703a867526a>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf_train_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_tf_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_tf_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_tf_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0meval_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf_eval_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_tensor'"
     ]
    }
   ],
   "source": [
    "train_features = {x: tf_train_dataset[x].to_tensor() for x in tokenizer.model_input_names}\n",
    "train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, y_train))\n",
    "train_tf_dataset = train_tf_dataset.shuffle(len(tf_train_dataset)).batch(8)\n",
    "\n",
    "eval_features = {x: tf_eval_dataset[x].to_tensor() for x in tokenizer.model_input_names}\n",
    "eval_tf_dataset = tf.data.Dataset.from_tensor_slices((eval_features, y_eval))\n",
    "eval_tf_dataset = eval_tf_dataset.batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "49da42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9cca896f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'with_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-a1746cd0a083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(tf_train_dataset, y_test.with_format(\"tensorflow\"), \n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_eval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tensorflow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           batch_size=8, epochs=3)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5476\u001b[0m         ):\n\u001b[1;32m   5477\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5478\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'with_format'"
     ]
    }
   ],
   "source": [
    "model.fit(tf_train_dataset, y_test.with_format(\"tensorflow\"), \n",
    "          validation_data=(tf_eval_dataset, y_eval.with_format(\"tensorflow\")),\n",
    "          batch_size=8, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "23a50935",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-350fcae91df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa18af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b65bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d15e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b86d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_batch_short = tokenizer(\n",
    "    df_lst_short, \n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0818f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_outputs_short = tf_model(tf_batch_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed733e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_outputs_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tf.nn.softmax(tf_outputs_short.logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e550f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rev = []\n",
    "for i, val in enumerate(results):\n",
    "    res_rev.append(int(val[1] >= 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb664272",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "(res_rev - df['review_sentiments'][:200])[150:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef1eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
